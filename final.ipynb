{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddf0392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "print(\"âœ“ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511269c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and balance dataset\n",
    "df = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "df = df[['Category', 'Message']]\n",
    "df.columns = ['Category', 'Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b2b17e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Balanced dataset: 1494 messages\n",
      "Distribution:\n",
      "spam\n",
      "1    747\n",
      "0    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Downsample to balance\n",
    "df_spam = df[df['Category']=='spam']\n",
    "df_ham = df[df['Category']=='ham']\n",
    "df_ham_downsampled = df_ham.sample(df_spam.shape[0], random_state=42)\n",
    "df_balanced = pd.concat([df_ham_downsampled, df_spam]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_balanced['spam'] = df_balanced['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
    "\n",
    "print(f\"âœ“ Balanced dataset: {df_balanced.shape[0]} messages\")\n",
    "print(f\"Distribution:\\n{df_balanced['spam'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bcd6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Preprocessing defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "def build_vocabulary(texts, min_freq=1, max_vocab_size=3000):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = preprocess_text(text)\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    most_common = counter.most_common(max_vocab_size)\n",
    "    filtered_words = [word for word, freq in most_common if freq >= min_freq]\n",
    "    \n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    for idx, word in enumerate(filtered_words, start=2):\n",
    "        vocab[word] = idx\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "print(\"âœ“ Preprocessing defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ff8fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Dataset class\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=50):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens = preprocess_text(self.texts[idx])\n",
    "        indices = [self.vocab.get(word, self.vocab['<UNK>']) for word in tokens]\n",
    "        \n",
    "        if len(indices) < self.max_len:\n",
    "            indices = indices + [self.vocab['<PAD>']] * (self.max_len - len(indices))\n",
    "        else:\n",
    "            indices = indices[:self.max_len]\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(indices, dtype=torch.long),\n",
    "            torch.tensor(int(self.labels[idx]), dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "print(\"âœ“ Dataset defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bab9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Simplified LSTM Model\n",
    "class EmailClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=100, hidden_dim=100):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, (hidden, _) = self.lstm(embedded)\n",
    "        dropped = self.dropout(hidden[-1])\n",
    "        output = self.fc(dropped)\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "print(\"âœ“ Model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d4a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Train: 1195, Test: 299\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Split data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df_balanced['Message'].tolist(),\n",
    "    df_balanced['spam'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_balanced['spam']\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Train: {len(train_texts)}, Test: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6ba5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Vocabulary: 3002 words\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Build vocab and loaders\n",
    "vocab = build_vocabulary(train_texts)\n",
    "print(f\"âœ“ Vocabulary: {len(vocab)} words\")\n",
    "\n",
    "train_dataset = EmailDataset(train_texts, train_labels, vocab, max_len=50)\n",
    "test_dataset = EmailDataset(test_texts, test_labels, vocab, max_len=50)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd23a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Device: cuda\n",
      "âœ“ Learning rate: 0.0005\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 8: Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EmailClassifier(vocab_size=len(vocab)).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)  # Lower learning rate\n",
    "\n",
    "print(f\"âœ“ Device: {device}\")\n",
    "print(f\"âœ“ Learning rate: 0.0005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc625252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "Epoch  1/30 | Loss: 0.6937 | Train: 0.486 | Test: 0.502 | Spam: 1.000 | Ham: 0.007 | Preds: S=298.0 H=1\n",
      "Epoch  2/30 | Loss: 0.6922 | Train: 0.517 | Test: 0.498 | Spam: 0.000 | Ham: 0.993 | Preds: S=1.0 H=298\n",
      "Epoch  3/30 | Loss: 0.6921 | Train: 0.495 | Test: 0.502 | Spam: 1.000 | Ham: 0.007 | Preds: S=298.0 H=1\n",
      "Epoch  4/30 | Loss: 0.6915 | Train: 0.505 | Test: 0.505 | Spam: 1.000 | Ham: 0.013 | Preds: S=297.0 H=2\n",
      "Epoch  5/30 | Loss: 0.6894 | Train: 0.500 | Test: 0.505 | Spam: 0.987 | Ham: 0.027 | Preds: S=293.0 H=6\n",
      "Epoch  6/30 | Loss: 0.6983 | Train: 0.540 | Test: 0.502 | Spam: 1.000 | Ham: 0.007 | Preds: S=298.0 H=1\n",
      "Epoch  7/30 | Loss: 0.6908 | Train: 0.490 | Test: 0.505 | Spam: 1.000 | Ham: 0.013 | Preds: S=297.0 H=2\n",
      "Epoch  8/30 | Loss: 0.6899 | Train: 0.510 | Test: 0.505 | Spam: 1.000 | Ham: 0.013 | Preds: S=297.0 H=2\n",
      "Epoch  9/30 | Loss: 0.6900 | Train: 0.509 | Test: 0.505 | Spam: 1.000 | Ham: 0.013 | Preds: S=297.0 H=2\n",
      "Epoch 10/30 | Loss: 0.6898 | Train: 0.505 | Test: 0.505 | Spam: 1.000 | Ham: 0.013 | Preds: S=297.0 H=2\n",
      "Epoch 11/30 | Loss: 0.6890 | Train: 0.522 | Test: 0.505 | Spam: 1.000 | Ham: 0.013 | Preds: S=297.0 H=2\n",
      "Epoch 12/30 | Loss: 0.6890 | Train: 0.490 | Test: 0.515 | Spam: 0.940 | Ham: 0.093 | Preds: S=276.0 H=23\n",
      "Epoch 13/30 | Loss: 0.6382 | Train: 0.685 | Test: 0.722 | Spam: 0.839 | Ham: 0.607 | Preds: S=184.0 H=115\n",
      "Epoch 14/30 | Loss: 0.5430 | Train: 0.756 | Test: 0.746 | Spam: 0.879 | Ham: 0.613 | Preds: S=189.0 H=110\n",
      "Epoch 15/30 | Loss: 0.5567 | Train: 0.775 | Test: 0.753 | Spam: 0.738 | Ham: 0.767 | Preds: S=145.0 H=154\n",
      "Epoch 16/30 | Loss: 0.5051 | Train: 0.803 | Test: 0.779 | Spam: 0.658 | Ham: 0.900 | Preds: S=113.0 H=186\n",
      "Epoch 17/30 | Loss: 0.4740 | Train: 0.827 | Test: 0.789 | Spam: 0.819 | Ham: 0.760 | Preds: S=158.0 H=141\n",
      "Epoch 18/30 | Loss: 0.4352 | Train: 0.840 | Test: 0.789 | Spam: 0.919 | Ham: 0.660 | Preds: S=188.0 H=111\n",
      "Epoch 19/30 | Loss: 0.4260 | Train: 0.842 | Test: 0.753 | Spam: 0.966 | Ham: 0.540 | Preds: S=213.0 H=86\n",
      "Epoch 20/30 | Loss: 0.4395 | Train: 0.827 | Test: 0.763 | Spam: 0.953 | Ham: 0.573 | Preds: S=206.0 H=93\n",
      "Epoch 21/30 | Loss: 0.3947 | Train: 0.855 | Test: 0.806 | Spam: 0.913 | Ham: 0.700 | Preds: S=181.0 H=118\n",
      "Epoch 22/30 | Loss: 0.3933 | Train: 0.855 | Test: 0.766 | Spam: 0.946 | Ham: 0.587 | Preds: S=203.0 H=96\n",
      "Epoch 23/30 | Loss: 0.4114 | Train: 0.843 | Test: 0.776 | Spam: 0.946 | Ham: 0.607 | Preds: S=200.0 H=99\n",
      "Epoch 24/30 | Loss: 0.3848 | Train: 0.862 | Test: 0.763 | Spam: 0.940 | Ham: 0.587 | Preds: S=202.0 H=97\n",
      "Epoch 25/30 | Loss: 0.3734 | Train: 0.863 | Test: 0.759 | Spam: 0.953 | Ham: 0.567 | Preds: S=207.0 H=92\n",
      "Epoch 26/30 | Loss: 0.3926 | Train: 0.850 | Test: 0.776 | Spam: 0.940 | Ham: 0.613 | Preds: S=198.0 H=101\n",
      "Epoch 27/30 | Loss: 0.3588 | Train: 0.878 | Test: 0.799 | Spam: 0.933 | Ham: 0.667 | Preds: S=189.0 H=110\n",
      "Epoch 28/30 | Loss: 0.3374 | Train: 0.880 | Test: 0.813 | Spam: 0.926 | Ham: 0.700 | Preds: S=183.0 H=116\n",
      "Epoch 29/30 | Loss: 0.3332 | Train: 0.891 | Test: 0.806 | Spam: 0.933 | Ham: 0.680 | Preds: S=187.0 H=112\n",
      "Epoch 30/30 | Loss: 0.3233 | Train: 0.893 | Test: 0.806 | Spam: 0.933 | Ham: 0.680 | Preds: S=187.0 H=112\n",
      "================================================================================\n",
      "âœ“ Best accuracy: 0.8127\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Training with detailed monitoring\n",
    "num_epochs = 30\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    train_spam_preds = 0\n",
    "    train_ham_preds = 0\n",
    "    \n",
    "    for texts, labels in train_loader:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        preds = (outputs > 0.5).float()\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "        train_spam_preds += preds.sum().item()\n",
    "        train_ham_preds += (preds == 0).sum().item()\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    test_spam_correct = 0\n",
    "    test_spam_total = 0\n",
    "    test_ham_correct = 0\n",
    "    test_ham_total = 0\n",
    "    test_spam_preds = 0\n",
    "    test_ham_preds = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for texts, labels in test_loader:\n",
    "            texts, labels = texts.to(device), labels.to(device)\n",
    "            outputs = model(texts).squeeze()\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            test_correct += (preds == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "            test_spam_preds += preds.sum().item()\n",
    "            test_ham_preds += (preds == 0).sum().item()\n",
    "            \n",
    "            spam_mask = labels == 1\n",
    "            ham_mask = labels == 0\n",
    "            \n",
    "            if spam_mask.sum() > 0:\n",
    "                test_spam_correct += (preds[spam_mask] == labels[spam_mask]).sum().item()\n",
    "                test_spam_total += spam_mask.sum().item()\n",
    "            \n",
    "            if ham_mask.sum() > 0:\n",
    "                test_ham_correct += (preds[ham_mask] == labels[ham_mask]).sum().item()\n",
    "                test_ham_total += ham_mask.sum().item()\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    test_acc = test_correct / test_total\n",
    "    spam_recall = test_spam_correct / test_spam_total if test_spam_total > 0 else 0\n",
    "    ham_recall = test_ham_correct / test_ham_total if test_ham_total > 0 else 0\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:2d}/{num_epochs} | Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Train: {train_acc:.3f} | Test: {test_acc:.3f} | \"\n",
    "          f\"Spam: {spam_recall:.3f} | Ham: {ham_recall:.3f} | \"\n",
    "          f\"Preds: S={test_spam_preds} H={test_ham_preds}\")\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.cpu(), 'email_classifier_best.pth')\n",
    "        model.to(device)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ“ Best accuracy: {best_acc:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c08d52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: email_classifier.pth, vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Save\n",
    "torch.save(model.cpu(), 'email_classifier.pth')\n",
    "with open('vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "print(\"âœ… Saved: email_classifier.pth, vocab.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3821b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“§ Predictions:\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸš« Spam (83.0%, prob=0.830): FREE! Win Â£1000 cash prize now! Call immediately\n",
      "âœ… Ham (96.8%, prob=0.032): Hey, meeting at 3pm tomorrow\n",
      "ðŸš« Spam (83.0%, prob=0.830): URGENT: Click here to verify your account now\n",
      "âœ… Ham (96.8%, prob=0.032): Can you send the report please\n",
      "ðŸš« Spam (83.0%, prob=0.830): Congratulations! You won a free iPhone!\n",
      "ðŸš« Spam (83.0%, prob=0.830): Thanks for your help yesterday\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸŽ‰ Done! Run: streamlit run app.py\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Test\n",
    "def predict(text, model, vocab):\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    tokens = preprocess_text(text)\n",
    "    indices = [vocab.get(w, vocab['<UNK>']) for w in tokens]\n",
    "    \n",
    "    if len(indices) < 50:\n",
    "        indices += [vocab['<PAD>']] * (50 - len(indices))\n",
    "    else:\n",
    "        indices = indices[:50]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prob = model(torch.tensor([indices], dtype=torch.long)).item()\n",
    "    \n",
    "    label = \"Spam\" if prob > 0.5 else \"Ham\"\n",
    "    conf = prob if prob > 0.5 else 1 - prob\n",
    "    return label, conf, prob\n",
    "    \n",
    "tests = [\n",
    "    \"FREE! Win Â£1000 cash prize now! Call immediately\",\n",
    "    \"Hey, meeting at 3pm tomorrow\",\n",
    "    \"URGENT: Click here to verify your account now\",\n",
    "    \"Can you send the report please\",\n",
    "    \"Congratulations! You won a free iPhone!\",\n",
    "    \"Thanks for your help yesterday\"\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ“§ Predictions:\\n\" + \"-\"*80)\n",
    "for msg in tests:\n",
    "    label, conf, prob = predict(msg, model, vocab)\n",
    "    emoji = \"ðŸš«\" if label == \"Spam\" else \"âœ…\"\n",
    "    print(f\"{emoji} {label} ({conf:.1%}, prob={prob:.3f}): {msg[:50]}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Done! Run: streamlit run app.py\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
